import { exec } from 'child_process';
import { promisify } from 'util';
import * as path from 'path';
import * as fs from 'fs';
import { promises as fsPromises } from 'fs';
import { fileURLToPath } from 'url';

const execAsync = promisify(exec);
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function findPython(): Promise<string> {
  const venvPython = path.join('.venv', 'Scripts', 'python.exe');
  const commands = [venvPython, 'py', 'python', 'python3'];

  for (const cmd of commands) {
    try {
      // For the venv python, check if the file exists before trying to execute
      if (cmd === venvPython && !fs.existsSync(venvPython)) {
        continue;
      }
      const { stdout } = await execAsync(`"${cmd}" --version`);
      console.log(`‚úÖ Python found using "${cmd}": ${stdout.trim()}`);
      return cmd;
    } catch {
      // Command not found, try the next one
    }
  }
  console.error('‚ùå Python is required but not found. Please install Python and ensure it is in your PATH.');
  process.exit(1);
}

async function checkDependencies(pythonCmd: string) {
  console.log('üêç Checking Python module path...');
  try {
    const { stdout } = await execAsync(`"${pythonCmd}" -c "import sys; print(sys.path)"`);
    console.log(stdout);
  } catch (e) {
    console.error('Could not get python path');
  }
  console.log('üîç Checking for required Python packages...');
  const requiredPackages = ['torch', 'transformers', 'sentencepiece', 'huggingface-hub'];
  const missingPackages: string[] = [];

  for (const pkg of requiredPackages) {
    try {
      await execAsync(`"${pythonCmd}" -c "import ${pkg}"`);
      console.log(`‚úÖ ${pkg} is installed`);
    } catch {
      console.log(`‚ö†Ô∏è  Package "${pkg}" not found.`);
      missingPackages.push(pkg);
    }
  }

  if (missingPackages.length > 0) {
    console.error('\n‚ùå Some required Python packages are missing.');
    console.error('Please install them manually by running the following command:');
    console.error(`\n  "${pythonCmd}" -m pip install ${missingPackages.join(' ')}\n`);
    process.exit(1);
  }
}

async function downloadModel() {
  try {
    console.log('--- SCRIPT START ---');
    console.log('üöÄ Starting MentaLLaMA model setup...');

    // Check Python installation
    console.log('--- CHECKING PYTHON ---');
    const pythonCmd = await findPython();
    console.log(`--- PYTHON CHECKED: Using command "${pythonCmd}" ---`);

    // Check and install required Python packages
    console.log('--- CHECKING DEPENDENCIES ---');
    await checkDependencies(pythonCmd);
    console.log('--- DEPENDENCIES CHECKED ---');

    // Get the path to the Python script
    const scriptPath = path.join(__dirname, 'download-model.py');

    // Create models directory if it doesn't exist
    console.log('--- CREATING MODELS DIRECTORY ---');
    const modelsDir = path.join(process.cwd(), 'models');
    try {
      await fsPromises.mkdir(modelsDir, { recursive: true });
      console.log(`üìÅ Created models directory at: ${modelsDir}`);
    } catch (error) {
      if ((error as NodeJS.ErrnoException).code !== 'EEXIST') {
        throw error;
      }
    }

    console.log('‚¨áÔ∏è  Starting model download (this may take a while, ~13GB)...');

    // Run the Python script
    const { stderr } = await execAsync(
      `"${pythonCmd}" "${scriptPath}"`,
      { maxBuffer: 1024 * 1024 * 10 } // 10MB buffer
    );

    if (stderr) {
      console.error('‚ö†Ô∏è  Warning during download:', stderr);
    }

    console.log('‚úÖ Model setup completed successfully!');
    console.log('üí° You can now start the server with: npm run dev');

    // Verify the model files
    await verifyModelFiles();

  } catch (error) {
    console.error('‚ùå Error setting up model:', (error as Error).message);
    console.log('\nTroubleshooting tips:');
    console.log('1. Make sure you have enough disk space (at least 15GB free)');
    console.log('2. Check your internet connection');
    console.log('3. Try running the script again');
    console.log('4. If the download fails, you can manually download the model from Hugging Face');
    console.log('   and place it in the models/ directory');
    process.exit(1);
  }
}

async function verifyModelFiles() {
  console.log('üîç Verifying model files...');
  const requiredFiles = [
    'config.json',
    'pytorch_model.bin',
    'tokenizer.json',
    'tokenizer_config.json',
    'special_tokens_map.json',
    'generation_config.json'
  ];
  
  const modelPath = path.join(process.cwd(), 'models', 'MentaLLaMA-chat-7B');
  
  try {
    const files = await fsPromises.readdir(modelPath);
    const missingFiles = requiredFiles.filter(file => !files.includes(file));
    
    if (missingFiles.length > 0) {
      console.warn('‚ö†Ô∏è  Some model files are missing:', missingFiles);
      console.log('Please make sure the model was downloaded correctly.');
      return false;
    }
    
    console.log('‚úÖ All required model files are present');
    return true;
  } catch (error) {
    console.error('‚ùå Error verifying model files:', (error as Error).message);
    return false;
  }
}

// Run the download
downloadModel();
